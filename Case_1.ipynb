{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPl+2wk1PwY4QVwZvqvfkwM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alvaroiramirez/Harvard_DataMining_Business_Student/blob/master/Case_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqHkjwly9lRT"
      },
      "outputs": [],
      "source": [
        "#' Author: Ted Kwartler\n",
        "#' Date: 2-14-2019\n",
        "#' Purpose: OKCupid Case Supplemental\n",
        "#'\n",
        "#'\n",
        "#' Student: Alvaro Ramirez\n",
        "#' Class: CSCI E-96\n",
        "\n",
        "#' Exploratory Data Analysis (EDA)\n",
        "#' -------------------------------\n",
        "\n",
        "\n",
        "# ENVIRONMENT SETUP\n",
        "\n",
        "# libraries\n",
        "library(dplyr)\n",
        "library(ggplot2)\n",
        "library(ggthemes)\n",
        "library(leaflet)\n",
        "library(leaflet.extras)\n",
        "library(mapproj)\n",
        "library(lubridate)\n",
        "library(radiant.data)\n",
        "library(DataExplorer)\n",
        "library(stringr)\n",
        "library(esquisse)\n",
        "library(tidyr)\n",
        "library(knitr)\n",
        "\n",
        "# Set working directory\n",
        "setwd(\"/Users/alvaroramirez/Library/CloudStorage/OneDrive-Personal/estudio/Harvard/Classes/CSCI E-96/CSCI E-96/Cases/Fall/I Ok Cupid\")\n",
        "\n",
        "\n",
        "# DATA IMPORT\n",
        "\n",
        "# Load OK Cupid data into memory\n",
        "profiles <- read.csv(\"profiles.csv\", stringsAsFactors = FALSE)\n",
        "latlon <- read.csv(\"LatLon.csv\", stringsAsFactors = FALSE)\n",
        "\n",
        "\n",
        "# DATA STRUCTURE\n",
        "\n",
        "# profiles.csv\n",
        "summary(profiles)\n",
        "\n",
        "# LatLon.csv\n",
        "summary(latlon)\n",
        "\n",
        "# Explore profiles\n",
        "str(profiles)\n",
        "\n",
        "# Explore latlon\n",
        "str(latlon)\n",
        "\n",
        "# NOTE: latlon and profiles have a one-to-many relationship. The field used to\n",
        "#       generate this link between both tables is 'location'.\n",
        "\n",
        "# Summarize the number of missing values in each column\n",
        "missing_summary <- sapply(profiles, function(x) sum(is.na(x)))\n",
        "missing_percentage <- sapply(profiles, function(x) mean(is.na(x)) * 100)\n",
        "\n",
        "# Create a summary table of missing values\n",
        "missing_data <- data.frame(\n",
        "  Column = names(profiles),\n",
        "  MissingValues = missing_summary,\n",
        "  MissingPercentage = missing_percentage\n",
        ")\n",
        "\n",
        "print(missing_data)\n",
        "\n",
        "\n",
        "# Values used in categorical columns\n",
        "\n",
        "# Function to calculate count and percentage for each unique value, handling NA values\n",
        "create_df_with_counts <- function(column) {\n",
        "\n",
        "  # Replace NA values with a placeholder ('<NA>')\n",
        "  column_clean <- ifelse(is.na(column), '<NA>', column)\n",
        "\n",
        "  # Get unique values including '<NA>' placeholder for NA\n",
        "  unique_values <- unique(column_clean)\n",
        "\n",
        "  # Create a dataframe with the unique values and their counts\n",
        "  df <- data.frame(\n",
        "    UniqueValue = unique_values,\n",
        "    Count = sapply(unique_values, function(x) sum(column_clean == x))\n",
        "  )\n",
        "\n",
        "  # Calculate the percentage for each value\n",
        "  df$Percentage <- (df$Count / length(column)) * 100\n",
        "\n",
        "  # Return both the dataframe and the number of unique categories\n",
        "  return(list(df = df, num_categories = length(unique_values)))\n",
        "}\n",
        "\n",
        "# Function to print the number of categories and the dataframe for each column\n",
        "print_df_with_category_count <- function(df_list, column_name) {\n",
        "  cat(\"Number of categories for '\", column_name, \"': \", df_list$num_categories, \"\\n\", sep = \"\")\n",
        "  print(df_list$df)\n",
        "  cat(\"\\n\")\n",
        "}\n",
        "\n",
        "# Create dataframes for each specified field with counts and percentages, and print the results\n",
        "\n",
        "# 'body_type'\n",
        "df_body_type <- create_df_with_counts(profiles$body_type)\n",
        "print_df_with_category_count(df_body_type, 'body_type')\n",
        "\n",
        "# 'diet'\n",
        "df_diet <- create_df_with_counts(profiles$diet)\n",
        "print_df_with_category_count(df_diet, 'diet')\n",
        "\n",
        "# 'drinks'\n",
        "df_drinks <- create_df_with_counts(profiles$drinks)\n",
        "print_df_with_category_count(df_drinks, 'drinks')\n",
        "\n",
        "# 'drugs'\n",
        "df_drugs <- create_df_with_counts(profiles$drugs)\n",
        "print_df_with_category_count(df_drugs, 'drugs')\n",
        "\n",
        "# 'education'\n",
        "df_education <- create_df_with_counts(profiles$education)\n",
        "print_df_with_category_count(df_education, 'education')\n",
        "\n",
        "# 'ethnicity'\n",
        "df_ethnicity <- create_df_with_counts(profiles$ethnicity)\n",
        "print_df_with_category_count(df_ethnicity, 'ethnicity')\n",
        "\n",
        "# 'job'\n",
        "df_job <- create_df_with_counts(profiles$job)\n",
        "print_df_with_category_count(df_job, 'job')\n",
        "\n",
        "# 'location'\n",
        "df_location <- create_df_with_counts(profiles$location)\n",
        "print_df_with_category_count(df_location, 'location')\n",
        "\n",
        "# 'offspring'\n",
        "df_offspring <- create_df_with_counts(profiles$offspring)\n",
        "print_df_with_category_count(df_offspring, 'offspring')\n",
        "\n",
        "# 'orientation'\n",
        "df_orientation <- create_df_with_counts(profiles$orientation)\n",
        "print_df_with_category_count(df_orientation, 'orientation')\n",
        "\n",
        "# 'pets'\n",
        "df_pets <- create_df_with_counts(profiles$pets)\n",
        "print_df_with_category_count(df_pets, 'pets')\n",
        "\n",
        "# 'religion'\n",
        "df_religion <- create_df_with_counts(profiles$religion)\n",
        "print_df_with_category_count(df_religion, 'religion')\n",
        "\n",
        "# 'sex'\n",
        "df_sex <- create_df_with_counts(profiles$sex)\n",
        "print_df_with_category_count(df_sex, 'sex')\n",
        "\n",
        "# 'sign'\n",
        "df_sign <- create_df_with_counts(profiles$sign)\n",
        "print_df_with_category_count(df_sign, 'sign')\n",
        "\n",
        "# 'smokes'\n",
        "df_smokes <- create_df_with_counts(profiles$smokes)\n",
        "print_df_with_category_count(df_smokes, 'smokes')\n",
        "\n",
        "# 'speaks'\n",
        "df_speaks <- create_df_with_counts(profiles$speaks)\n",
        "print_df_with_category_count(df_speaks, 'speaks')\n",
        "\n",
        "# Save the 'df_speaks' dataframe as a CSV file\n",
        "write.csv(df_speaks$df, file = \"speaks.csv\", row.names = FALSE)\n",
        "\n",
        "# 'status'\n",
        "df_status <- create_df_with_counts(profiles$status)\n",
        "print_df_with_category_count(df_status, 'status')\n",
        "\n",
        "\n",
        "### Language analysis - Start\n",
        "\n",
        "# Load necessary libraries\n",
        "library(dplyr)\n",
        "library(tidyr)\n",
        "library(stringr)\n",
        "\n",
        "# Read the profiles.csv file\n",
        "# profiles <- read.csv(\"profiles.csv\")\n",
        "\n",
        "# Function to process the 'speaks' column\n",
        "process_speaks <- function(speaks) {\n",
        "  if (is.na(speaks) || speaks == \"\") {\n",
        "    # return(\"english\")\n",
        "    return(\"\")\n",
        "  }\n",
        "  # Split the speaks column by comma\n",
        "  languages <- unlist(strsplit(speaks, \",\"))\n",
        "  # Remove leading and trailing whitespace\n",
        "  languages <- str_trim(languages)\n",
        "  # Remove duplicates\n",
        "  languages <- unique(languages)\n",
        "  return(paste(languages, collapse = \", \"))\n",
        "}\n",
        "\n",
        "# Apply the function to the 'speaks' column\n",
        "profiles$speaks <- sapply(profiles$speaks, process_speaks)\n",
        "\n",
        "# 1. Count how many languages each person speaks\n",
        "profiles <- profiles %>%\n",
        "  mutate(language_count = sapply(strsplit(speaks, \", \"), length))\n",
        "\n",
        "# 2. Use 'english' if there is no value (already handled in process_speaks function)\n",
        "\n",
        "# 3. Count how many people speak each language\n",
        "language_counts <- profiles %>%\n",
        "  separate_rows(speaks, sep = \", \") %>%\n",
        "  group_by(speaks) %>%\n",
        "  summarise(count = n()) %>%\n",
        "  arrange(desc(count))\n",
        "\n",
        "# 4. Count how many people speak each language indicating their level\n",
        "language_level_counts <- profiles %>%\n",
        "  separate_rows(speaks, sep = \", \") %>%\n",
        "  mutate(language = str_extract(speaks, \"^[^()]+\"),\n",
        "         level = str_extract(speaks, \"\\\\(([^)]+)\\\\)\")) %>%\n",
        "  group_by(language, level) %>%\n",
        "  summarise(count = n()) %>%\n",
        "  arrange(language, desc(count))\n",
        "\n",
        "# Print the results\n",
        "print(profiles)\n",
        "print(language_counts)\n",
        "print(language_level_counts)\n",
        "\n",
        "# Exporting results\n",
        "write.csv(language_counts, \"language_counts.csv\", row.names = FALSE)\n",
        "write.csv(language_level_counts, \"language_level_counts.csv\", row.names = FALSE)\n",
        "\n",
        "\n",
        "# COUNT HOW MANY PEOPLE SPEAK EACH LANGUAGE\n",
        "\n",
        "# Function to process the 'speaks' column\n",
        "process_speaks <- function(speaks) {\n",
        "  if (is.na(speaks) || speaks == \"\") {\n",
        "    return(\"english\")\n",
        "  }\n",
        "  # Split the speaks column by comma\n",
        "  languages <- unlist(strsplit(speaks, \",\"))\n",
        "  # Remove leading and trailing whitespace and any extra spaces\n",
        "  languages <- str_trim(languages)\n",
        "  languages <- gsub(\"\\\\s+\", \"\", languages)\n",
        "  # Remove duplicates\n",
        "  languages <- unique(languages)\n",
        "  return(paste(languages, collapse = \", \"))\n",
        "}\n",
        "\n",
        "# Apply the function to the 'speaks' column\n",
        "profiles$speaks <- sapply(profiles$speaks, process_speaks)\n",
        "\n",
        "# 1. Count how many languages each person speaks\n",
        "profiles <- profiles %>%\n",
        "  mutate(language_count = sapply(strsplit(speaks, \", \"), length))\n",
        "\n",
        "# 2. Use 'english' if there is no value (already handled in process_speaks function)\n",
        "\n",
        "# 4. Count how many people speak each language indicating their level\n",
        "language_level_counts <- profiles %>%\n",
        "  separate_rows(speaks, sep = \", \") %>%\n",
        "  mutate(language = str_extract(speaks, \"^[^()]+\"),\n",
        "         level = str_extract(speaks, \"\\\\(([^)]+)\\\\)\")) %>%\n",
        "  group_by(language, level) %>%\n",
        "  summarise(count = n()) %>%\n",
        "  arrange(language, desc(count))\n",
        "\n",
        "# Print the totals for each language grouping all levels\n",
        "totals_per_language <- language_level_counts %>%\n",
        "  group_by(language) %>%\n",
        "  summarise(total_count = sum(count)) %>%\n",
        "  arrange(desc(total_count))\n",
        "\n",
        "print(totals_per_language)\n",
        "\n",
        "# Save the results in a CSV file\n",
        "write.csv(totals_per_language, \"totals_per_language.csv\", row.names = FALSE)\n",
        "\n",
        "\n",
        "\n",
        "### ### Language analysis - End\n",
        "\n",
        "## -----------------\n",
        "\n",
        "\n",
        "# Read the profiles.csv file\n",
        "profiles <- read.csv(\"profiles.csv\")\n",
        "\n",
        "# Define the order of fluency levels\n",
        "fluency_levels <- c(NA, \"(poorly)\", \"(okay)\", \"(fluently)\")\n",
        "\n",
        "\n",
        "# Function to process the 'speaks' column\n",
        "process_speaks <- function(speaks) {\n",
        "\n",
        "  # print(paste(\"0 - speaks: \", speaks, sep = \"\")) ### STEP 0\n",
        "\n",
        "  if (is.na(speaks) || speaks == \"\") {\n",
        "    # return(\"english\")\n",
        "    return(\"\")\n",
        "  }\n",
        "\n",
        "  # print(paste(\"1 - speaks: \", speaks, sep = \"\")) ### STEP 1\n",
        "\n",
        "  # Split the speaks column by comma\n",
        "  languages <- unlist(strsplit(speaks, \",\"))\n",
        "\n",
        "  # print(paste(\"2 - languages: \", languages, sep = \"\")) ### STEP 2\n",
        "\n",
        "  # Remove leading and trailing whitespace and any extra spaces\n",
        "  languages <- str_trim(languages)\n",
        "  languages <- gsub(\"\\\\s+\", \"\", languages)\n",
        "\n",
        "  # print(paste(\"3 - languages: \", languages, sep = \"\")) ### STEP 3\n",
        "\n",
        "  # Create a data frame of languages and levels\n",
        "  languages_df <- data.frame(language = str_extract(languages, \"^[^()]+\"),\n",
        "                             level = str_extract(languages, \"\\\\(([^)]+)\\\\)\"))\n",
        "\n",
        "  # print(paste(\"4 - languages_df: \", languages_df, sep = \"\")) ### STEP 4\n",
        "  # kable(languages_df, caption = 'STEP 4')\n",
        "\n",
        "  # Ensure 'english' is included with no level if not already present\n",
        "  if (!any(grepl(\"^english\", tolower(languages_df$language)))) {\n",
        "    languages_df <- rbind(languages_df, data.frame(language = \"english\", level = NA))\n",
        "  }\n",
        "\n",
        "  # print(paste(\"5 - languages_df: \", languages_df, sep = \"\")) ### STEP 5\n",
        "  # kable(languages_df, caption = 'STEP 5')\n",
        "\n",
        "\n",
        "  # Remove duplicates and keep the highest level, handle NA levels correctly\n",
        "  cleaned_languages_df <- languages_df %>%\n",
        "    mutate(level = factor(level, levels = fluency_levels, ordered = TRUE)) %>%\n",
        "    group_by(language) %>%\n",
        "    filter(if(all(is.na(level))) TRUE else level == max(level, na.rm = TRUE)) %>%\n",
        "    distinct(language, .keep_all = TRUE) %>%  # Remove duplicates after filtering\n",
        "    ungroup()  # Ungroup the dataframe\n",
        "\n",
        "  # Print the cleaned dataframe\n",
        "  # print(paste(\"6 - languages_df: \", cleaned_languages_df, sep = \"\")) ### STEP 6\n",
        "  # kable(cleaned_languages_df, caption = 'STEP 6')\n",
        "\n",
        "  # Combine languages and levels back into a single string\n",
        "  languages <- paste(cleaned_languages_df$language, ifelse(is.na(cleaned_languages_df$level), \"\", paste0(cleaned_languages_df$level)), sep = \"\", collapse = \", \")\n",
        "\n",
        "  # print(paste(\"7 - languages: \", languages, sep = \"\")) ### STEP 7\n",
        "\n",
        "  return(languages)\n",
        "}\n",
        "\n",
        "\n",
        "### TEST ###\n",
        "str <- 'english, english (okay), spanish (okay), spanish (poorly), french, italian (fluently), chinese (fluently), chinese (fluently), thai, thai'\n",
        "print(process_speaks(str))\n",
        "############\n",
        "\n",
        "\n",
        "# Create a new dataset to avoid overwriting the original 'profiles' dataset\n",
        "profiles_processed <- profiles ########\n",
        "profiles_processed$speaks <- sapply(profiles_processed$speaks, process_speaks)\n",
        "\n",
        "# 1. Count how many languages each person speaks\n",
        "profiles_processed <- profiles_processed %>%\n",
        "  mutate(language_count = sapply(strsplit(speaks, \", \"), length))\n",
        "\n",
        "# 4. Count how many people speak each language indicating their level\n",
        "language_level_counts <- profiles_processed %>%\n",
        "  separate_rows(speaks, sep = \", \") %>%\n",
        "  mutate(language = str_extract(speaks, \"^[^()]+\"),\n",
        "         level = str_extract(speaks, \"\\\\(([^)]+)\\\\)\")) %>%\n",
        "  group_by(language, level) %>%\n",
        "  summarise(count = n_distinct(row_number())) %>%\n",
        "  arrange(language, desc(count))\n",
        "\n",
        "# Calculate the totals for each language spoken\n",
        "totals_per_language <- language_level_counts %>%\n",
        "  group_by(language) %>%\n",
        "  summarise(total_count = sum(count)) %>%\n",
        "  arrange(desc(total_count))\n",
        "\n",
        "# Print the results\n",
        "print(language_level_counts)\n",
        "print(totals_per_language)\n",
        "\n",
        "# Save the results in CSV files\n",
        "write.csv(language_level_counts, \"speaks_language_level_counts.csv\", row.names = FALSE)\n",
        "write.csv(totals_per_language, \"speaks_totals_per_language.csv\", row.names = FALSE)\n",
        "write.csv(profiles_processed, \"speaks_profiles_processed.csv\", row.names = FALSE)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## -----------------\n",
        "\n",
        "\n",
        "# Let's start with analyzing the 'age' column\n",
        "\n",
        "# Summary of age column\n",
        "summary(profiles$age)\n",
        "\n",
        "# Check how many records have unrealistic values (age < 18 or age > 100)\n",
        "invalid_age <- profiles %>%\n",
        "  filter(age < 18 | age > 100)\n",
        "\n",
        "# Calculate percentage of invalid age records\n",
        "invalid_age_count <- nrow(invalid_age)\n",
        "invalid_age_percentage <- (invalid_age_count / nrow(profiles)) * 100\n",
        "\n",
        "cat(\"Number of invalid age records: \", invalid_age_count, \"\\n\")\n",
        "cat(\"Percentage of invalid age records: \", invalid_age_percentage, \"%\\n\")\n",
        "\n",
        "# Visualize age data with a boxplot to identify outliers\n",
        "ggplot(profiles, aes(x = factor(0), y = age)) +\n",
        "  geom_boxplot(fill = \"lightblue\") +\n",
        "  theme_minimal() +\n",
        "  labs(title = \"Boxplot of Age\", x = \"\", y = \"Age\")\n",
        "\n",
        "# Plot age distribution with a histogram\n",
        "ggplot(profiles, aes(x = age)) +\n",
        "  geom_histogram(binwidth = 1, fill = \"skyblue\", color = \"black\") +\n",
        "  theme_minimal() +\n",
        "  labs(title = \"Age Distribution\", x = \"Age\", y = \"Count\")\n",
        "\n",
        "# Analysis of height column\n",
        "\n",
        "# Summary of height column\n",
        "summary(profiles$height)\n",
        "\n",
        "# Check for invalid height values (less than 50 inches or greater than 95 inches)\n",
        "invalid_height <- profiles %>%\n",
        "  filter(height < 50 | height > 95)\n",
        "\n",
        "# Calculate percentage of invalid height records\n",
        "invalid_height_count <- nrow(invalid_height)\n",
        "invalid_height_percentage <- (invalid_height_count / nrow(profiles)) * 100\n",
        "\n",
        "cat(\"Number of invalid height records: \", invalid_height_count, \"\\n\")\n",
        "cat(\"Percentage of invalid height records: \", invalid_height_percentage, \"%\\n\")\n",
        "\n",
        "# Visualize height data with a boxplot to detect outliers\n",
        "ggplot(profiles, aes(x = factor(0), y = height)) +\n",
        "  geom_boxplot(fill = \"salmon\") +\n",
        "  theme_minimal() +\n",
        "  labs(title = \"Boxplot of Height\", x = \"\", y = \"Height (in inches)\")\n",
        "\n",
        "# Plot height distribution with a histogram\n",
        "ggplot(profiles, aes(x = height)) +\n",
        "  geom_histogram(binwidth = 1, fill = \"salmon\", color = \"black\") +\n",
        "  theme_minimal() +\n",
        "  labs(title = \"Height Distribution\", x = \"Height\", y = \"Count\")\n",
        "\n",
        "# Income analysis\n",
        "\n",
        "# Summary of income column\n",
        "summary(profiles$income)\n",
        "\n",
        "# Check for invalid income values (income > 1,000,000)\n",
        "invalid_income <- profiles %>%\n",
        "  filter(income > 1000000)\n",
        "\n",
        "# Calculate percentage of invalid income records\n",
        "invalid_income_count <- nrow(invalid_income)\n",
        "invalid_income_percentage <- (invalid_income_count / nrow(profiles)) * 100\n",
        "\n",
        "cat(\"Number of invalid income records: \", invalid_income_count, \"\\n\")\n",
        "cat(\"Percentage of invalid income records: \", invalid_income_percentage, \"%\\n\")\n",
        "\n",
        "# Visualize income with a boxplot\n",
        "ggplot(profiles, aes(x = factor(0), y = income)) +\n",
        "  geom_boxplot(fill = \"lightgreen\") +\n",
        "  theme_minimal() +\n",
        "  labs(title = \"Boxplot of Income\", x = \"\", y = \"Income\")\n",
        "\n",
        "# Plot income distribution\n",
        "ggplot(profiles, aes(x = income)) +\n",
        "  geom_histogram(binwidth = 10000, fill = \"lightgreen\", color = \"black\") +\n",
        "  theme_minimal() +\n",
        "  labs(title = \"Income Distribution\", x = \"Income\", y = \"Count\")\n",
        "\n",
        "# Now let's check how many records have complete data (i.e., no missing values in any column)\n",
        "complete_records <- profiles[complete.cases(profiles), ]\n",
        "\n",
        "# Calculate the percentage of records with complete data\n",
        "complete_data_count <- nrow(complete_records)\n",
        "complete_data_percentage <- (complete_data_count / nrow(profiles)) * 100\n",
        "\n",
        "cat(\"Number of complete records: \", complete_data_count, \"\\n\")\n",
        "cat(\"Percentage of complete records: \", complete_data_percentage, \"%\\n\")\n",
        "\n",
        "# Now, we perform some combined column analysis. Let's analyze 'age' vs 'income'\n",
        "ggplot(profiles, aes(x = age, y = income)) +\n",
        "  geom_point(alpha = 0.5, color = \"blue\") +\n",
        "  theme_minimal() +\n",
        "  labs(title = \"Age vs Income\", x = \"Age\", y = \"Income\")\n",
        "\n",
        "# Also analyze the relationship between 'education' and 'income'\n",
        "ggplot(profiles, aes(x = education, y = income, fill = education)) +\n",
        "  geom_boxplot() +\n",
        "  theme_minimal() +\n",
        "  labs(title = \"Education Level vs Income\", x = \"Education Level\", y = \"Income\")\n",
        "\n",
        "# Now analyze 'diet' vs 'drinks' to see the distribution between these two habits\n",
        "diet_drinks_table <- table(profiles$diet, profiles$drinks)\n",
        "print(diet_drinks_table)\n",
        "\n",
        "# Plot diet vs drinks\n",
        "ggplot(profiles, aes(x = diet, fill = drinks)) +\n",
        "  geom_bar(position = \"dodge\") +\n",
        "  theme_minimal() +\n",
        "  labs(title = \"Diet vs Drinking Habits\", x = \"Diet\", y = \"Count\")\n",
        "\n",
        "# Check the geographic distribution by merging with the LatLon dataset\n",
        "profiles_latlon <- merge(profiles, latlon, by = \"location\")\n",
        "\n",
        "# Summarize combined dataset after merging\n",
        "summary(profiles_latlon)\n",
        "\n",
        "# Map visualization: Display users on a map based on location\n",
        "leaflet(profiles_latlon) %>%\n",
        "  addTiles() %>%\n",
        "  addCircleMarkers(~lon, ~lat, radius = 2, color = \"blue\",\n",
        "                   fillOpacity = 0.5, popup = ~location) %>%\n",
        "  addProviderTiles(providers$Stamen.TonerLite)\n",
        "\n",
        "# Analyzing 'sex' and 'income' combination to check income distribution by gender\n",
        "ggplot(profiles, aes(x = sex, y = income, fill = sex)) +\n",
        "  geom_boxplot() +\n",
        "  theme_minimal() +\n",
        "  labs(title = \"Income Distribution by Gender\", x = \"Gender\", y = \"Income\")\n",
        "\n",
        "# Analyzing 'last_online' column: Check activity in the last year\n",
        "profiles$last_online <- as.Date(profiles$last_online, format = \"%Y-%m-%d\")\n",
        "\n",
        "# Filter active users (who were online in the last year)\n",
        "active_users <- profiles %>%\n",
        "  filter(last_online > Sys.Date() - years(1))\n",
        "\n",
        "# Plot number of active users by location\n",
        "ggplot(active_users, aes(x = location)) +\n",
        "  geom_bar(fill = \"orange\") +\n",
        "  coord_flip() +\n",
        "  theme_minimal() +\n",
        "  labs(title = \"Active Users by Location\", x = \"Location\", y = \"Count\")\n",
        "\n",
        "# Exporting cleaned and merged data for future use\n",
        "write.csv(profiles_latlon, \"profiles_latlon_cleaned.csv\", row.names = FALSE)\n",
        "\n",
        "# Generate summary report using DataExplorer\n",
        "create_report(profiles_latlon)\n",
        "\n",
        "# End of R code\n",
        "\n",
        "##################\n",
        "\n",
        "\n",
        "\n",
        "##### I would do some basic EDA and plotting of individual vars then move to more complex interactions # nolint: line_length_linter.\n",
        "table(profiles$orientation)\n",
        "hist(profiles$age)\n",
        "\n",
        "##### Example 2 way EDA\n",
        "table(profiles$age, profiles$orientation)\n",
        "\n",
        "#### Missing in income & quick mean imputation example; you can still use vtreat instead to clean all\n",
        "#### this data but we are only exploring not modeling so maybe dont do it for this case. # nolint: line_length_linter.\n",
        "sum(is.na(profiles$income))\n",
        "profiles$income[is.na(profiles$income)] <- mean(profiles$income, na.rm = TRUE)\n",
        "\n",
        "##### Feature Engineer relationship status & education if you thought there was a connection # nolint: line_length_linter.\n",
        "profiles$statEDU <- paste(profiles$status, profiles$education, sep = \"_\")\n",
        "table(profiles$statEDU)\n",
        "\n",
        "##### Enrich with one of the new data sets, you may want to do this with the other csv # nolint: line_length_linter.\n",
        "moreData <- left_join(profiles, latlon, by = \"location\") # nolint: object_name_linter, line_length_linter.\n",
        "head(moreData)\n",
        "\n",
        "#### You can use complete.cases() to identify records without NA if that is the route\n",
        "#### you want to explore.  Of course you can use a function covered in class to visualize\n",
        "#### the variables with the hightest % of NA so you could drop those instead of all rows\n",
        "#### with an NA. # nolint: line_length_linter.\n",
        "completeMoreData <- moreData[complete.cases(moreData), ] # nolint: object_name_linter, line_length_linter.\n",
        "completeMoreData\n",
        "nrow(completeMoreData)\n",
        "dim(completeMoreData)\n",
        "# End\n",
        "\n",
        "\n",
        "Artifacts\n",
        "1. R code\n",
        "2. Word document\n",
        "3. PowerPoint presentation\n",
        "4. Presenter's notes\n",
        "5. YouTube video script\n"
      ]
    }
  ]
}